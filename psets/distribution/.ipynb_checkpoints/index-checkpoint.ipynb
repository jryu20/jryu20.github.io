{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b5211c5-b8eb-4eaf-9902-cd078e257600",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Distribution Magic\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "author: \"Jun Ryu\"\n",
    "date: \"2023-02-15\"\n",
    "categories: [statistics]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3c412e-2315-4179-99a6-b92180704e23",
   "metadata": {},
   "source": [
    "Suppose one has a collection of numbers $x_1,\\ldots, x_n$, which are taken to be independent samples from the $N(\\mu, \\sigma_0^2)$ distribution. \n",
    "\n",
    "> Here, $\\sigma_0^2$ is known, but $\\mu$ is unknown. Using the prior distribution $M âˆ¼ N(\\mu_0, \\rho_0^2)$ for $\\mu$, derive the formula for the [posterior distribution](https://en.wikipedia.org/wiki/Posterior_probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e76728-22d4-45db-b26a-53e357e6baaf",
   "metadata": {},
   "source": [
    "To solve this problem, we will utilize the concept of proportionality ($\\propto$). More specifically, we have the following equation regarding the posterior distribution: \n",
    "\n",
    "$$f_{\\Theta|X}(\\theta|x) \\propto f_{X|\\Theta}(x|\\theta)f_{\\Theta}(\\theta)$$\n",
    "$$\\text{Posterior density} \\propto \\text{Likelihood} \\times \\text{Prior density}$$\n",
    "\n",
    "We will first find the *likelihood*. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20d2d3-25c0-4731-8cd4-90c771b20b00",
   "metadata": {},
   "source": [
    "## 1. Likelihood\n",
    "\n",
    "We have that: $$f(x_i|\\mu, \\sigma_0^2) \\propto {\\kappa}e^{-{(x_i-\\mu)^2}/{2\\sigma_0^2}}$$ since each $x_i$ is a sample from a normal distribution. (Here, $\\kappa$ is just a normalizing constant.)\n",
    "\n",
    "Our likelihood is the product of all the PDFs (probability density functions) for $x_1,\\ldots,x_n$:\n",
    "\n",
    "$$ f(x|\\mu, \\sigma_0^2) = \\prod_{i=1}^n f(x_i|\\mu, \\sigma_0^2) \\propto {\\kappa}e^{-{\\sum_{i=1}^n(x_i-\\mu)^2}/{2\\sigma_0^2}} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a248f1-c640-4fda-ac4f-0b88acc62043",
   "metadata": {},
   "source": [
    "## 2. Posterior Density\n",
    "\n",
    "Using the above, we will derive the posterior density. Given that our prior distribution is also normal, we have:\n",
    "\n",
    "$$ P(\\mu|x_1,\\ldots,x_n) = f(x|\\mu, \\sigma_0^2) \\cdot g(\\mu|\\mu_0, \\rho_0^2) $$\n",
    "$$ \\propto {\\kappa}e^{-{\\sum_{i=1}^n(x_i-\\mu)^2}/{2\\sigma_0^2} - (\\mu-\\mu_0)^2/2\\rho_0^2} $$\n",
    "\n",
    "Now, we just need to simplify the exponent:\n",
    "\n",
    "$$ -\\frac{1}{2}\\left(\\frac{\\sum_{i=1}^n(x_i-\\mu)^2}{\\sigma_0^2} + \\frac{(\\mu-\\mu_0)^2}{\\rho_0^2}\\right) $$\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{\\sum_{i=1}^n x_i^2 - 2n\\bar{x}\\mu+n\\mu^2}{\\sigma_0^2} + \\frac{\\mu^2-2\\mu\\mu_0+\\mu_0^2}{\\rho_0^2}\\right) $$\n",
    "\n",
    "From here, we can drop all terms without $\\mu$ because those are part of our normalizing constant:\n",
    "\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{-2n\\bar{x}\\mu+n\\mu^2}{\\sigma_0^2} + \\frac{\\mu^2-2\\mu\\mu_0}{\\rho_0^2}\\right) $$\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{-2n\\bar{x}\\mu\\rho_0^2+n\\mu^2\\rho_0^2+\\mu^2\\sigma_0^2-2\\mu\\mu_0\\sigma_0^2}{\\sigma_0^2\\rho_0^2}\\right) $$\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{\\mu^2(n\\rho_0^2+\\sigma_0^2)-2\\mu(\\mu_0\\sigma_0^2+n\\bar{x}\\rho_0^2)}{\\sigma_0^2\\rho_0^2}\\right) $$\n",
    "\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{\\mu^2-2\\mu\\frac{(\\mu_0\\sigma_0^2+n\\bar{x}\\rho_0^2)}{(n\\rho_0^2+\\sigma_0^2)}}{\\frac{\\sigma_0^2\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724dbf55-fc07-4afc-a5c4-59291216f6a5",
   "metadata": {},
   "source": [
    "## 3. Final Distribution\n",
    "\n",
    "Here, we will use a neat trick called *complete the square*. We do this by introducing a constant term $\\kappa_0$ (a term that does not involve $\\mu$) to the numerator:\n",
    "\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{\\mu^2-2\\mu\\frac{(\\mu_0\\sigma_0^2+n\\bar{x}\\rho_0^2)}{(n\\rho_0^2+\\sigma_0^2)}+\\kappa_0}{\\frac{\\sigma_0^2\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}}\\right) $$\n",
    "\n",
    "::: {.callout-note}\n",
    "To be more specific, $\\kappa_0 := \\left(\\frac{\\mu_0\\sigma_0^2+n\\bar{x}\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}\\right)^2$, and indeed, this term does not have $\\mu$ and does not affect the distribution.\n",
    ":::\n",
    "\n",
    "$$ = -\\frac{1}{2}\\left(\\frac{\\left(\\mu-\\frac{\\mu_0\\sigma_0^2+n\\bar{x}\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}\\right)^2}{\\frac{\\sigma_0^2\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}}\\right) $$\n",
    "\n",
    "We notice that the above form looks a lot like the PDF of a **normal distribution**. Thus, our posterior PDF can be represented as ${\\kappa}e^{{-(\\mu-c)^2}/{2\\tau^2}}$, where:\n",
    "\n",
    "$$ \\boxed{c = \\frac{\\mu_0\\sigma_0^2+n\\bar{x}\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}, \\tau^2 = \\frac{\\sigma_0^2\\rho_0^2}{n\\rho_0^2+\\sigma_0^2}}$$\n",
    "\n",
    "So, we conclude that our posterior distribution is $\\boxed{N(c, \\tau^2)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609bc9b-32b5-4daf-8a43-52fccbb7368e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
